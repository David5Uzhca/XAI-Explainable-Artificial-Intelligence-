# XAI ‚Äì Interpretaci√≥n de Modelos de Machine Learning y Deep Learning

## Descripci√≥n general del proyecto

Este proyecto presenta un **estudio t√©cnico y experimental sobre Explainable Artificial Intelligence (XAI)**, aplicando y comparando modelos de *Machine Learning cl√°sico* y *Deep Learning* sobre **datos estructurados** e **im√°genes**, con el objetivo de **interpretar, analizar y explicar las predicciones** de cada modelo.

El trabajo se centra en responder una pregunta clave:

> ¬øC√≥mo y por qu√© un modelo toma una decisi√≥n, m√°s all√° de su precisi√≥n?

Para ello, se desarrollaron **dos pr√°cticas complementarias**, integradas bajo un mismo marco conceptual de explicabilidad.

---

## Objetivos

### Objetivo general

Analizar y comparar modelos predictivos desde la perspectiva de **XAI**, evaluando su desempe√±o y su capacidad de explicaci√≥n.

### Objetivos espec√≠ficos

* Aplicar modelos interpretables y no interpretables en distintos tipos de datos.
* Identificar **caracter√≠sticas importantes** y **factores clave** en las predicciones.
* Visualizar y analizar explicaciones globales y locales.
* Evidenciar las limitaciones de la interpretabilidad en modelos complejos.

---

## Marco conceptual: XAI

**Explainable Artificial Intelligence (XAI)** busca hacer transparentes los modelos de IA, permitiendo:

* Comprender decisiones del modelo
* Generar confianza
* Detectar sesgos
* Facilitar la toma de decisiones humanas

Este proyecto contrasta:

* **Modelos inherentemente interpretables** (√Årboles, Random Forest, SVM)
* **Modelos de alta complejidad** (Redes Neuronales, CNN)

---

## Pr√°ctica 1: Datos estructurados

### Dataset

**Online Shoppers Purchasing Intention Dataset**
[https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset](https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset)

* Variables num√©ricas y categ√≥ricas
* Variable objetivo: `Revenue` (0 = No compra, 1 = Compra)
* Problema: **Clasificaci√≥n binaria**

### Modelos aplicados

* **Random Forest / √Årbol de Decisi√≥n**
* **Red Neuronal Artificial (MLP)**

### Flujo del proceso

1. Carga de datos y an√°lisis exploratorio (EDA)
2. Preprocesamiento:

   * Variables dummy
   * Escalado con `StandardScaler`
3. Entrenamiento de modelos
4. Evaluaci√≥n de m√©tricas
5. An√°lisis XAI

### Caracter√≠sticas importantes (XAI)

* `PageValue` ‚Üí Variable m√°s influyente
* `ExitRates` y `BounceRates`
* `ProductRelated` y duraci√≥n
* `VisitorType`

### Resultados clave

* Ambos modelos identifican **PageValue** como factor determinante
* El **√Årbol de Decisi√≥n** reduce falsos negativos
* Mejor interpretaci√≥n de patrones l√≥gicos de compra

### Ventajas y desventajas

**Random Forest / √Årbol**

* ‚úî Alta interpretabilidad
* ‚úî Explicaci√≥n directa de decisiones
* ‚úñ Menor capacidad para relaciones muy complejas

**Red Neuronal**

* ‚úî Mayor capacidad de representaci√≥n
* ‚úñ Modelo tipo *caja negra*

### Conclusi√≥n pr√°ctica 1

Los modelos basados en √°rboles resultan m√°s adecuados cuando la **explicabilidad es prioritaria**, especialmente en contextos de negocio.

---

## Pr√°ctica 2: Clasificaci√≥n de im√°genes

### Dataset

**Oxford-IIIT Pet Dataset**
[https://www.kaggle.com/datasets/tanlikesmath/the-oxfordiiit-pet-dataset](https://www.kaggle.com/datasets/tanlikesmath/the-oxfordiiit-pet-dataset)

* Im√°genes RGB de perros y gatos
* Alta variabilidad visual
* Problema: **Clasificaci√≥n de im√°genes**

### Modelos aplicados

* **SVM (LinearSVC)**
* **CNN (Convolutional Neural Network)**

### Flujo del proceso

1. Carga de im√°genes
2. Conversi√≥n a escala de grises
3. Redimensionamiento (64√ó64)
4. Vectorizaci√≥n (SVM)
5. Entrenamiento de modelos
6. Visualizaci√≥n XAI

### Enfoque XAI

* **SVM**: visualizaci√≥n de pesos como mapas de calor
* **CNN**: an√°lisis de regiones activadas (conceptual)

### Resultados clave

* SVM genera mapas ruidosos
* Falta de alineaci√≥n espacial en im√°genes
* Los p√≠xeles no representan sem√°ntica fija

### Limitaciones detectadas

* El SVM busca correlaciones espaciales r√≠gidas
* No captura jerarqu√≠as visuales
* Explicabilidad matem√°tica ‚â† explicabilidad sem√°ntica

### Conclusi√≥n pr√°ctica 2

Aunque el SVM es explicable matem√°ticamente, **no es adecuado para visi√≥n por computador compleja**. Las CNN son superiores, pero requieren t√©cnicas XAI adicionales.

---

## Relaci√≥n global con XAI

Este proyecto demuestra que:

* La precisi√≥n no es suficiente
* La interpretabilidad depende del tipo de dato
* XAI act√∫a como puente entre modelos y usuarios

| Tipo de modelo | Precisi√≥n | Explicabilidad |
| -------------- | --------- | -------------- |
| √Årboles        | Media     | Alta           |
| Random Forest  | Alta      | Media-Alta     |
| SVM            | Media     | Media          |
| CNN            | Muy alta  | Baja (sin XAI) |

---

## üìÅ Estructura del proyecto

```
Proyecto-XAI
 ‚î£ üìÇ data
 ‚î£ üìÇ notebooks
 ‚îÉ ‚î£ DecisionTree.ipynb
 ‚îÉ ‚î£ SMV_Uzhca.ipynb
 ‚î£ üìÑ README.md
 ‚îó üìÑ X-ai.pdf
```

---

## Autores

* **David Uzhca**
* **Domenika Delgado**
* **Irar Nankamai**

---

## Conclusi√≥n general

La **Explainable AI** es esencial para una adopci√≥n responsable de modelos de IA. Este proyecto evidencia que **comprender el porqu√© de una predicci√≥n es tan importante como el resultado mismo**, especialmente en contextos reales donde la confianza y la transparencia son fundamentales.
